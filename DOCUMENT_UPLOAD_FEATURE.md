# Feature: Upload DokumentÃ³w - Alternatywne Å¹rÃ³dÅ‚o Danych

## ğŸ“‹ PrzeglÄ…d

Nowa funkcjonalnoÅ›Ä‡ umoÅ¼liwia przesÅ‚anie istniejÄ…cych dokumentÃ³w firmowych jako alternatywÄ™ do rÄ™cznego wypeÅ‚niania formularza Step 1. Claude API automatycznie wyciÄ…ga, segreguje i mapuje dane z dokumentÃ³w na strukturÄ™ audytu BFA.

---

## ğŸ¯ Cel

- **Problem:** Klienci czÄ™sto majÄ… juÅ¼ przygotowane dokumenty (raporty, analizy, dane procesowe)
- **RozwiÄ…zanie:** Upload dokumentÃ³w â†’ Automatyczna ekstrakcja danych przez Claude â†’ Review i edycja â†’ Analiza
- **KorzyÅ›Ä‡:** OszczÄ™dnoÅ›Ä‡ czasu (2-5 minut zamiast 15-20 minut rÄ™cznego wypeÅ‚niania)

---

## ğŸš€ FunkcjonalnoÅ›Ä‡

### 1. Wspierane Formaty PlikÃ³w

| Format | Rozszerzenie | Typ parsera | Uwagi |
|--------|--------------|-------------|-------|
| Excel | `.xlsx`, `.xls` | openpyxl + pandas | Wszystkie sheety, tabele, dane |
| PDF | `.pdf` | PyPDF2 | Ekstrakcja tekstu (OCR niedostÄ™pne) |
| Text | `.txt` | chardet | Auto-detection encodingu |
| Markdown | `.md` | chardet | Ekstrakcja sekcji (#) |
| CSV | `.csv` | csv.DictReader | Auto-detection delimitera |

### 2. Limity

- **Maksymalnie:** 10 plikÃ³w
- **Rozmiar pliku:** 50 MB per plik
- **CaÅ‚kowity rozmiar:** 200 MB
- **Tokeny Claude:** 200,000 (zwiÄ™kszony z 16,000)
- **Extended Thinking budget:** 50,000 tokenÃ³w

---

## ğŸ”§ Architektura

### Backend Components

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ file_parsers.py          # Parsery dla rÃ³Å¼nych formatÃ³w
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ document.py               # UploadedDocument, DocumentProcessingResult
â”‚   â”‚
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ documents.py              # Endpoints: upload, get-result, delete
â”‚   â”‚
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ claude_service.py         # extract_data_from_documents()
```

### Frontend Components

```
frontend/src/components/
â”œâ”€â”€ Step1Form.tsx                     # GÅ‚Ã³wny komponent z wyborem trybu
â”œâ”€â”€ DocumentUploadInterface.tsx       # Upload drag & drop
â””â”€â”€ ReviewExtractedData.tsx           # PrzeglÄ…d i edycja wyciÄ…gniÄ™tych danych
```

---

## ğŸ“¡ API Endpoints

### 1. Upload i przetwarzanie dokumentÃ³w

```http
POST /api/projects/{project_id}/documents/upload
Content-Type: multipart/form-data

files: File[]
```

**Response:**
```json
{
  "project_id": 1,
  "processing_result_id": 42,
  "files_uploaded": 3,
  "extracted_data": { ... },
  "confidence_scores": {
    "organization": 0.95,
    "digital_maturity": 0.75,
    "pain_points": 0.88,
    ...
  },
  "missing_fields": [
    {
      "field": "budget.amount_range",
      "reason": "Brak informacji w dokumentach",
      "suggested_question": "Jaki budÅ¼et macie na automatyzacjÄ™?"
    }
  ],
  "processing_summary": {
    "documents_analyzed": 3,
    "total_pages": 47,
    "key_findings": [...],
    "data_quality": "good",
    "recommendations": [...]
  },
  "processing_time_seconds": 123
}
```

### 2. Pobranie rezultatu przetwarzania

```http
GET /api/projects/{project_id}/documents/processing-result/{result_id}
```

### 3. Lista przesÅ‚anych dokumentÃ³w

```http
GET /api/projects/{project_id}/documents/uploaded
```

### 4. UsuniÄ™cie dokumentu

```http
DELETE /api/projects/{project_id}/documents/{document_id}
```

---

## ğŸ¤– Claude Ekstrakcja Danych

### Proces

1. **Parsing:** KaÅ¼dy plik jest parsowany odpowiednim parserem
2. **Aggregacja:** Wszystkie dane sÄ… agregowane w jeden prompt
3. **Claude Analysis:** Extended Thinking z budÅ¼etem 50k tokenÃ³w
4. **Mapping:** Claude mapuje dane na strukturÄ™ `InitialAssessmentData`
5. **Confidence Scoring:** KaÅ¼da sekcja dostaje score 0.0-1.0
6. **Missing Fields Detection:** Identyfikacja brakujÄ…cych pÃ³l

### Confidence Scoring

| Score | Znaczenie | Opis |
|-------|-----------|------|
| 1.0 | Wysoka pewnoÅ›Ä‡ | Dane explicite w dokumentach |
| 0.7-0.9 | Dobra pewnoÅ›Ä‡ | Dane wywnioskowane z kontekstu |
| 0.4-0.6 | Åšrednia pewnoÅ›Ä‡ | Dane czÄ™Å›ciowe |
| 0.0-0.3 | Niska pewnoÅ›Ä‡ | Brak danych w dokumentach |

### Output Structure

```typescript
{
  extracted_data: InitialAssessmentData,
  confidence_scores: {
    organization: 0.95,
    digital_maturity: 0.75,
    pain_points: 0.88,
    goals: 0.65,
    budget: 0.50,
    timeline: 0.40,
    resources: 0.70,
    constraints: 0.60,
    processes_identified: 0.85
  },
  missing_fields: [
    {
      field: "budget.amount_range",
      reason: "Brak informacji w dokumentach",
      suggested_question: "Jaki budÅ¼et macie na automatyzacjÄ™?"
    }
  ],
  processing_summary: {
    documents_analyzed: 3,
    total_pages: 47,
    key_findings: ["..."],
    data_quality: "good",
    recommendations: ["..."]
  }
}
```

---

## ğŸ’» Frontend Flow

### 1. Mode Selection (Step1Form)

User wybiera:
- **Formularz manualny** â†’ WypeÅ‚nia 20 pytaÅ„ rÄ™cznie
- **PrzeÅ›lij dokumenty** â†’ Upload interface

### 2. Document Upload (DocumentUploadInterface)

- Drag & drop lub select files
- Walidacja: format, rozmiar, liczba plikÃ³w
- Upload do backendu
- Progress indicator (2-5 minut)
- Przekierowanie do Review

### 3. Review Extracted Data (ReviewExtractedData)

- **Confidence indicators** per sekcja
- **Data quality badge** (excellent/good/fair/poor)
- **Processing summary** z key findings
- **Missing fields alerts** z sugerowanymi pytaniami
- **Editable fields** (moÅ¼liwoÅ›Ä‡ korekty)
- **Confirm button** â†’ Claude analysis â†’ Step 2

---

## ğŸ—„ï¸ Database Schema

### UploadedDocument

```sql
CREATE TABLE uploaded_documents (
    id INTEGER PRIMARY KEY,
    project_id INTEGER REFERENCES projects(id),
    filename VARCHAR(255),
    file_path VARCHAR(500),
    file_type VARCHAR(10),        -- excel, pdf, txt, md, csv
    file_size BIGINT,
    uploaded_at TIMESTAMP DEFAULT NOW()
);
```

### DocumentProcessingResult

```sql
CREATE TABLE document_processing_results (
    id INTEGER PRIMARY KEY,
    project_id INTEGER REFERENCES projects(id),
    extracted_data JSONB,
    confidence_scores JSONB,
    missing_fields JSONB,
    processing_summary JSONB,
    tokens_used INTEGER,
    processing_time_seconds INTEGER,
    created_at TIMESTAMP DEFAULT NOW()
);
```

---

## ğŸ“¦ Instalacja

### Backend

```bash
cd backend
pip install -r requirements.txt
```

Nowe zaleÅ¼noÅ›ci:
- `openpyxl==3.1.2` - Excel parsing
- `pandas==2.0.3` - Data processing
- `PyPDF2==3.0.1` - PDF parsing
- `chardet==5.2.0` - Encoding detection

### Frontend

Brak dodatkowych zaleÅ¼noÅ›ci (uÅ¼ywamy natywnego File API).

---

## ğŸ§ª Testowanie

### Test 1: Upload Excel

```bash
# Przygotuj plik Excel z danymi organizacji
# Kolumny: Parametr, WartoÅ›Ä‡
# Wiersze: Nazwa firmy, BranÅ¼a, WielkoÅ›Ä‡, etc.

# Upload przez UI lub curl:
curl -X POST "http://localhost:8000/api/projects/1/documents/upload" \
  -F "files=@dane_firmy.xlsx"
```

### Test 2: Upload PDF

```bash
# Przygotuj PDF raport z opisem firmy i procesÃ³w
curl -X POST "http://localhost:8000/api/projects/1/documents/upload" \
  -F "files=@raport_procesow.pdf"
```

### Test 3: Multiple Files

```bash
curl -X POST "http://localhost:8000/api/projects/1/documents/upload" \
  -F "files=@dane_organizacyjne.xlsx" \
  -F "files=@opis_procesow.pdf" \
  -F "files=@problemy_i_cele.md"
```

---

## âš¡ Performance

### Benchmarks

| Scenariusz | Pliki | Rozmiar | Czas przetwarzania |
|------------|-------|---------|-------------------|
| 1 Excel (5 sheets) | 1 | 2 MB | ~60 sekund |
| 3 PDF (total 50 pages) | 3 | 15 MB | ~150 sekund |
| 5 mixed files | 5 | 25 MB | ~180 sekund |
| 10 files (max) | 10 | 100 MB | ~300 sekund |

### Optymalizacja

- **Parsing**: Lokalny (szybki)
- **Claude API**: Extended Thinking (powolny ale dokÅ‚adny)
- **Caching**: Brak (kaÅ¼dy upload = nowa analiza)
- **Timeout**: 10 minut (600 sekund)

---

## ğŸ”’ Security

### Walidacja

- âœ… File extension whitelist
- âœ… File size limits
- âœ… Total size limit
- âœ… Max files limit
- âœ… Path traversal protection (filename sanitization)

### Privacy

- Pliki zapisywane lokalnie w `./uploaded_documents/project_{id}/`
- Brak wysyÅ‚ania surowych plikÃ³w do Claude
- Tylko sparsowane dane tekstowe
- Automatyczne kasowanie plikÃ³w przy usuwaniu projektu (CASCADE)

---

## ğŸ› Troubleshooting

### Problem: "Unsupported file type"
**RozwiÄ…zanie:** SprawdÅº rozszerzenie pliku (tylko .xlsx, .xls, .pdf, .txt, .md, .csv)

### Problem: "File too large"
**RozwiÄ…zanie:** Zmniejsz rozmiar pliku (<50MB per plik, <200MB total)

### Problem: "Failed to parse Excel"
**RozwiÄ…zanie:** 
- SprawdÅº czy plik nie jest chroniony hasÅ‚em
- Upewnij siÄ™, Å¼e zawiera dane (nie jest pusty)
- Zainstaluj openpyxl: `pip install openpyxl pandas`

### Problem: "Failed to parse PDF"
**RozwiÄ…zanie:**
- PDF musi zawieraÄ‡ tekst (nie tylko obrazy - brak OCR)
- Zainstaluj PyPDF2: `pip install PyPDF2`

### Problem: "Low confidence scores"
**RozwiÄ…zanie:**
- Dodaj wiÄ™cej szczegÃ³Å‚Ã³w do dokumentÃ³w
- UÅ¼yj strukturyzowanych formatÃ³w (tabele w Excel/CSV)
- Dodaj headery/sekcje w Markdown
- UzupeÅ‚nij missing fields rÄ™cznie w Review

### Problem: "Processing takes too long"
**RozwiÄ…zanie:**
- Normalny czas: 2-5 minut dla 3-5 plikÃ³w
- Zmniejsz liczbÄ™/rozmiar plikÃ³w
- SprawdÅº Claude API limit rate
- Check backend logs dla errors

---

## ğŸ“ˆ Future Improvements

### Planowane

- [ ] OCR dla PDF ze skanami (pdf2image + pytesseract)
- [ ] Word documents support (.docx)
- [ ] Images support (.jpg, .png) z OCR
- [ ] Batch processing (kolejka)
- [ ] Caching results (redis)
- [ ] Preview plikÃ³w przed uploadem
- [ ] Progress websockets (realtime updates)
- [ ] Partial data save (draft mode)

### Opcjonalne

- [ ] AI-powered data correction suggestions
- [ ] Multi-language support
- [ ] Export extracted data to Excel template
- [ ] Comparison between manual form vs uploaded data
- [ ] Learning from user corrections (fine-tuning)

---

## ğŸ“š PrzykÅ‚ady UÅ¼ycia

### PrzykÅ‚ad 1: Firma produkcyjna

**Dokumenty:**
- `organizacja.xlsx` - dane firmy, struktura, systemy IT
- `procesy_produkcyjne.pdf` - opis linii produkcyjnych
- `problemy_i_cele.md` - Markdown z opisem wyzwaÅ„

**Rezultat:**
- Confidence: 88%
- Missing fields: budget, timeline
- Key findings: "8 procesÃ³w zidentyfikowanych, gÅ‚Ã³wny problem: rÄ™czne przepisywanie danych"

### PrzykÅ‚ad 2: Firma logistyczna

**Dokumenty:**
- `dane_firmowe.xlsx` - profil organizacji
- `kpi_raport.csv` - metryki procesowe
- `mapa_procesow.pdf` - diagram AS-IS

**Rezultat:**
- Confidence: 92%
- Missing fields: strategic initiatives
- Key findings: "Magazyn i transport - TOP priority, 45h/tydzieÅ„ manual work"

---

## ğŸ“ Best Practices

### Dla UÅ¼ytkownikÃ³w

1. **Strukturyzuj dane** - UÅ¼ywaj tabel, kolumn, sekcji
2. **Dodaj nagÅ‚Ã³wki** - W Markdown, Excel, CSV
3. **BÄ…dÅº szczegÃ³Å‚owy** - Im wiÄ™cej danych, tym lepsza ekstrakcja
4. **Mix formatÃ³w** - Excel (dane), PDF (opisy), MD (notatki)
5. **Nazwij pliki jasno** - `dane_organizacyjne.xlsx` zamiast `file123.xlsx`

### Dla DeveloperÃ³w

1. **Validate early** - Check files przed parsowaniem
2. **Handle errors gracefully** - Jeden zÅ‚y plik nie moÅ¼e zepsuÄ‡ caÅ‚oÅ›ci
3. **Log everything** - Debugging Claude ekstrakcji wymaga logÃ³w
4. **Monitor token usage** - 200k to duÅ¼o ale nie nieskoÅ„czonoÅ›Ä‡
5. **Test edge cases** - Puste pliki, corrupted files, huge files

---

## ğŸ“ Support

W razie problemÃ³w:
1. SprawdÅº logi backend (`uvicorn` terminal)
2. SprawdÅº logi frontend (Console F12)
3. Zweryfikuj Claude API key i rate limits
4. SprawdÅº `uploaded_documents/` folder permissions

---

**Wersja:** 2.1  
**Data:** 2025-10-26  
**Feature by:** BFA Audit App Team  
**Powered by:** Claude Sonnet 4.5 Extended Thinking (200k tokens, 50k thinking budget)
